{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as ss\n",
    "import nltk\n",
    "import re\n",
    "from nltk.util import ngrams\n",
    "#from word import Word\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "#import spacy\n",
    "#from spacy import displacy\n",
    "from collections import Counter\n",
    "#import en_core_web_sm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "#nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stopwords(text):\n",
    "    \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(text) \n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "    filtered_sentence = [] \n",
    "\n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    \n",
    "    return filtered_sentence\n",
    "            \n",
    "def buildMRC(fileName):\n",
    "    words = {}\n",
    "    with open(fileName) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    for i in range(0, len(lines)):\n",
    "        line = lines[i]\n",
    "        numScores = 0\n",
    "        nlet = int(line[0:2])\n",
    "        nphon = int(line[2:4])\n",
    "        nsyl = int(line[4])\n",
    "        kffreq = int(line[5:10])\n",
    "        kfcats = int(line[10:12])\n",
    "        kfsamps = int(line[12:15])\n",
    "        tlfreq = int(line[15:21])\n",
    "        bfreq = int(line[21:25])\n",
    "        fam = int(line[25:28])\n",
    "        conc = int(line[28:31])\n",
    "        imag = int(line[31:34])\n",
    "        meanc = int(line[34:37])\n",
    "        meanp = int(line[37:40])\n",
    "        aoa = int(line[40:43])\n",
    "        scores = [nlet, nphon, nsyl, kffreq, kfcats, kfsamps, tlfreq, bfreq, fam,\n",
    "            conc, imag, meanc, meanp, aoa]\n",
    "        #Count the number of non-zero scores for this entry\n",
    "        for score in scores:\n",
    "            if score != 0:\n",
    "                numScores += 1\n",
    "        word = extractWord(lines[i])\n",
    "        newWord = Word(nlet, nphon, nsyl, kffreq, kfcats, kfsamps,\n",
    "            tlfreq, bfreq, fam, conc, imag, meanc, meanp, aoa, numScores)\n",
    "\n",
    "        #Get the current entry in our DB for this word. If the word already\n",
    "        #exists in our DB, then compare the number of scores on record to our newWord\n",
    "        #If the newWord has more entries, it is considered to be more \"complete\"\n",
    "        #and therefore will replace the current entry\n",
    "        currentWord = words.get(word)\n",
    "        if(currentWord is not None):\n",
    "            if(currentWord.numScores < newWord.numScores):\n",
    "                words[word] = newWord\n",
    "        else:\n",
    "            words[word] = newWord\n",
    "    return words\n",
    "\n",
    "def extractWord(line):\n",
    "    index = 51\n",
    "    while line[index] != '|':\n",
    "        index += 1\n",
    "    return line[51:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_score(corpus,summaries,thresh = 0.4):\n",
    "    '''\n",
    "    checks ratio of words with (idf in corpus) > thresh present in the summaries\n",
    "    '''\n",
    "    scores=np.zeros(len(summaries))\n",
    "    vec=TfidfVectorizer(stop_words='english')\n",
    "    X=vec.fit_transform(corpus)\n",
    "    X=X>thresh\n",
    "    imp_words=ss.find(X)[1]\n",
    "    X2=vec.transform(summaries)\n",
    "    for row in X2:\n",
    "        found_words=np.intersect1d(imp_words,ss.find(X2[row])[1])\n",
    "        scores[row]=float(found_words.shape[0])/imp_words.shape[0]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_idf_values(corpus,summaries):\n",
    "    corpus_tokenized = tokenize_and_remove_stopwords(corpus.lower())\n",
    "    idf_values = {}\n",
    "    \n",
    "    N = len(corpus_tokenized)\n",
    "    for word in corpus_tokenized:\n",
    "        if word not in idf_values:\n",
    "            idf_values[word] = 1\n",
    "        else:\n",
    "            idf_values[word] += 1\n",
    "    \n",
    "    summaries_tokenized = []\n",
    "    \n",
    "    for summary in summaries:\n",
    "        summary_tokenized = tokenize_and_remove_stopwords(summary.lower())\n",
    "        summaries_tokenized.append(summary_tokenized)\n",
    "                \n",
    "    scores = np.zeros(len(summaries)) \n",
    "    for i,summary_tokenized in enumerate(summaries_tokenized):\n",
    "        num_words = len(summary_tokenized)\n",
    "        score = 0\n",
    "        for word in summary_tokenized:\n",
    "            if word in idf_values:\n",
    "                score = score + 1.0/idf_values[word]\n",
    "        if num_words == 0:\n",
    "            scores[i] = 0\n",
    "        else:\n",
    "            scores[i] = score/num_words\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = buildMRC('./mrc-psycholinguistics/mrc2.dct')\n",
    "def get_concr_score(summaries):\n",
    "    scores = np.zeros(len(summaries))\n",
    "    for i,summary in enumerate(summaries):\n",
    "        number_of_words = 0\n",
    "        concreteness_score = 0\n",
    "        for word in summary:\n",
    "            word_scores = db.get(word.upper())\n",
    "            if word_scores is not None:\n",
    "                number_of_words+=1\n",
    "                concreteness_score+=word_scores.get_concr_score()\n",
    "        if number_of_words != 0:  \n",
    "            scores[i] = (concreteness_score*1.0)/number_of_words\n",
    "        else:\n",
    "            scores[i] = 0\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_sim(corpus,summaries,n=2):\n",
    "    corpus = corpus.split()\n",
    "    scores=np.zeros(len(summaries))\n",
    "    bigram_corpus=set(ngrams(corpus,n))\n",
    "    for i,summ in enumerate(summaries):\n",
    "        summ = summ.split()\n",
    "        bigram_summ=set(ngrams(summ,n))\n",
    "        score=float(len(bigram_corpus.intersection(bigram_summ)))\n",
    "        score/=len(bigram_corpus)\n",
    "        scores[i] = score\n",
    "    return scores\n",
    "## TODO: make it memory efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_SUMBASIC_score(corpus,summaries):\n",
    "    \n",
    "    corpus_tokenized = tokenize_and_remove_stopwords(corpus.lower())\n",
    "    wordprob={}\n",
    "    idf_values = {}\n",
    "    \n",
    "    N = len(corpus_tokenized)\n",
    "    for word in corpus_tokenized:\n",
    "        if word not in wordprob:\n",
    "            wordprob[word] = 1 / float(N)\n",
    "        else:\n",
    "            wordprob[word] += 1 / float(N)\n",
    "        \n",
    "        if word not in idf_values:\n",
    "            idf_values[word] = 1\n",
    "        else:\n",
    "            idf_values[word] += 1\n",
    "    \n",
    "    summaries_tokenized = []\n",
    "    \n",
    "    \n",
    "    for summary in summaries:\n",
    "        summary_tokenized = tokenize_and_remove_stopwords(summary.lower())\n",
    "        summaries_tokenized.append(summary_tokenized)\n",
    "\n",
    "            \n",
    "                \n",
    "    scores = np.zeros(len(summaries)) \n",
    "    for i,summary_tokenized in enumerate(summaries_tokenized):\n",
    "        num_sen = len(re.split(r'[.!?]+', summaries[i]))\n",
    "        score = 0\n",
    "        for word in summary_tokenized:\n",
    "            if word in wordprob:\n",
    "                score = score + wordprob[word]*(1/idf_values[word])\n",
    "        scores[i] = score/num_sen\n",
    "    \n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NE_Frequency_Score(corpus,summaries):\n",
    "    \n",
    "    doc = nlp(corpus)\n",
    "    count_corpus = {}\n",
    "    for X in doc.ents:\n",
    "        if X.text not in count_corpus:\n",
    "            count_corpus[X.text] = 1\n",
    "        else:\n",
    "            count_corpus[X.text] +=1\n",
    "    \n",
    "    scores = []\n",
    "    for summary in summaries:\n",
    "        summary_named_entity = nlp(summary)\n",
    "        count_summary = {}\n",
    "        score = 0\n",
    "        for X in summary_named_entity.ents:\n",
    "            if X.text not in count_summary:\n",
    "                count_summary[X.text] = 1\n",
    "            else:\n",
    "                count_summary[X.text] += 1\n",
    "        for key in count_summary:\n",
    "            if key in count_corpus:\n",
    "                score += count_summary[key] * count_corpus[key]\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsa_scores(summaries):\n",
    "    scores=np.zeros(len(summaries))\n",
    "    for i,summary in enumerate(summaries):\n",
    "        summary.replace('?','.')\n",
    "        summary.replace('!','.')\n",
    "        scores[i] = lsa(summary.split('.'))\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perplexity_scores(summaries):\n",
    "    \n",
    "    scores=np.zeros(len(summaries))\n",
    "    for i,summary in enumerate(summaries):\n",
    "        scores[i] = lm.perplexity(summary)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa(summary):\n",
    "    n_components = 1 # assuming 1 'abstract components'\n",
    "    # find coherence between sentences of the summary\n",
    "    # send a list of SENTENCES of the summary\n",
    "    vec = CountVectorizer(stop_words='english')\n",
    "    lsa = TruncatedSVD(n_components,algorithm='arpack') \n",
    "    try:\n",
    "        X = vec.fit_transform(summary)\n",
    "    except:\n",
    "        return 0\n",
    "    X = np.array(X.toarray(),dtype='f')\n",
    "    try:\n",
    "        lsa.fit(X)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "    transforms = []\n",
    "    for sent in X:\n",
    "        transforms.append(lsa.transform(sent.reshape((1,-1))))\n",
    "\n",
    "    metric = 0.0\n",
    "    for i in range(len(transforms)-1):\n",
    "        running_sum = 0.\n",
    "        for j in range(n_components):\n",
    "            running_sum += cosine_similarity(np.array(transforms[i][j]).reshape((1,-1)),np.array(transforms[i+1][j]).reshape((1,-1)))[0][0]\n",
    "        metric += running_sum/n_components\n",
    "\n",
    "    metric/=len(summary)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suyash/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/decomposition/truncated_svd.py:192: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55950404 0.41310487 0.38740018 0.35764567 0.27269299 0.19949213]\n"
     ]
    }
   ],
   "source": [
    "output_baseline = pickle.load(open(\"./Summaries/output_baseline_temp.pkl\",\"rb\"),encoding='latin1')\n",
    "output_graph = pickle.load(open(\"./Summaries/output_graph_temp.pkl\",\"rb\"),encoding='latin1')\n",
    "output_pointer_gen = pickle.load(open(\"./Summaries/output_pointer_gen.pkl\",\"rb\"))\n",
    "output_rein_learn = pickle.load(open(\"./Summaries/output_rein_learn.pkl\",\"rb\"))\n",
    "output_openNMT = pickle.load(open(\"./Summaries/output_openNMT.pkl\",\"rb\"))\n",
    "output_struct_infused = pickle.load(open(\"./Summaries/output_struct_infused.pkl\",\"rb\"))\n",
    "\n",
    "concrete_scores = []\n",
    "n_gram_sim_scores = []\n",
    "sum_basic_scores = []\n",
    "NE_frequency_scores = []\n",
    "pennalized_scores = []\n",
    "average_idf_values_scores = []\n",
    "lsa_scores=[]\n",
    "for key in output_baseline.keys():\n",
    "    summaries = []\n",
    "    summaries.append(output_baseline[key][1])\n",
    "    if key in output_graph:\n",
    "        if type(output_graph[key][1]) != type([]):\n",
    "            summaries.append(output_graph[key][1])\n",
    "        else:\n",
    "            if len(output_graph[key][1]) == 0:\n",
    "                summaries.append(\"\")\n",
    "            else:\n",
    "                summaries.append(output_graph[key][1][0])\n",
    "    else:\n",
    "        summaries.append(\"\")\n",
    "    if key in output_pointer_gen:\n",
    "        summaries.append(output_pointer_gen[key][1])\n",
    "    else:\n",
    "        summaries.append(\"\")\n",
    "    if key in output_rein_learn:\n",
    "        summaries.append(output_rein_learn[key][1])\n",
    "    else:\n",
    "        summaries.append(\"\")\n",
    "    if key in output_openNMT:\n",
    "        summaries.append(output_openNMT[key][1])\n",
    "    else:\n",
    "        summaries.append(\"\")\n",
    "    if key in output_struct_infused:\n",
    "        summaries.append(output_struct_infused[key][1])\n",
    "    else:\n",
    "        summaries.append(\"\")\n",
    "    \n",
    "#     print([type(item) for item in summaries])\n",
    "#     print(\"Total number of summaries generated for \",key,\" is \",len(summaries))\n",
    "    corpus = [s for s in output_baseline[key][0].splitlines() if s]\n",
    "    lsa_scores.append(get_lsa_scores(summaries))\n",
    "print(np.array(lsa_scores).mean(axis=0))\n",
    "#     print([s for s in output_baseline[key][0].splitlines() if s])\n",
    "#     print(get_tfidf_score(corpus,summaries))\n",
    "#     concrete_scores.append(get_concr_score(summaries))\n",
    "#     n_gram_sim_scores.append(n_gram_sim(output_baseline[key][0],summaries))\n",
    "#     sum_basic_scores.append(get_SUMBASIC_score(output_baseline[key][0],summaries))\n",
    "#     NE_frequency_scores.append(get_NE_Frequency_Score(output_baseline[key][0],summaries))\n",
    "#     pennalized_scores.append(n_gram_sim(output_baseline[key][0],summaries,4))\n",
    "#     average_idf_values_scores.append(get_average_idf_values(output_baseline[key][0],summaries))\n",
    "\n",
    "#     break\n",
    "\n",
    "# concrete_scores = np.array(concrete_scores)\n",
    "# n_gram_sim_scores = np.array(n_gram_sim_scores)\n",
    "# sum_basic_scores = np.array(sum_basic_scores)\n",
    "# NE_frequency_scores = np.array(NE_frequency_scores)\n",
    "# pennalized_scores = np.array(pennalized_scores)\n",
    "# average_idf_values_scores = np.array(average_idf_values_scores)\n",
    "\n",
    "# print(np.mean(concrete_scores,axis=0))\n",
    "# print(np.mean(n_gram_sim_scores,axis=0))\n",
    "# print(np.mean(sum_basic_scores,axis=0))\n",
    "# print(np.mean(NE_frequency_scores,axis=0))\n",
    "# print(np.mean(pennalized_scores,axis = 0))\n",
    "# print(np.mean(average_idf_values_scores,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
